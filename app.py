import streamlit as st
import tempfile
import os
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from ebooklib import epub
from bs4 import BeautifulSoup

# --- ì´ˆê¸° ì„¤ì • ---
GEMINI_API_KEY = st.secrets.get("Key")
if not GEMINI_API_KEY:
    st.error("Gemini API key not found. Please add 'Key' to your secrets.")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)

@st.cache_resource
def load_gemini_model():
    """Gemini ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    return genai.GenerativeModel("models/gemini-1.5-flash")

@st.cache_resource
def load_embedder():
    """ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_gemini_model()
embedder = load_embedder()

# --- í•¨ìˆ˜ë“¤ ---
def extract_epub_chapters(epub_path):
    """
    ePub íŒŒì¼ì—ì„œ ì±•í„° ì œëª©ê³¼ ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ePub ëª©ì°¨(TOC), HTML <title> íƒœê·¸, ê·¸ë¦¬ê³  HTML í—¤ë”© íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬
    ê°€ì¥ ì •í™•í•œ ì±•í„° ì œëª©ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    book = epub.read_epub(epub_path)
    titles, chapters = [], []
    
    # ì±•í„° íŒŒì¼ ê²½ë¡œ(href)ì™€ í•´ë‹¹ ì œëª©ì„ ë§¤í•‘í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    toc_href_to_title = {}

    # Helper function to recursively process TOC entries and yield (href, title) pairs
    def process_toc_item_recursively(toc_entry_item):
        """
        Recursively processes an ePub TOC entry to extract its href and title.
        Handles EpubNavPoint, EpubHtml, and common tuple structures.
        """
        href = None
        title = None
        
        if isinstance(toc_entry_item, epub.EpubNavPoint):
            # í‘œì¤€ ëª©ì°¨ ë‚´ë¹„ê²Œì´ì…˜ í¬ì¸íŠ¸
            href = toc_entry_item.href
            title = toc_entry_item.title
            
            # í•˜ìœ„ ì±•í„°(ìì‹) ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
            for child in toc_entry_item.children:
                yield from process_toc_item_recursively(child)
                
        elif isinstance(toc_entry_item, epub.EpubHtml):
            # EpubHtml ê°ì²´ê°€ TOCì— ì§ì ‘ í¬í•¨ëœ ê²½ìš°
            href = toc_entry_item.href
            # EpubHtml ê°ì²´ì— 'title' ì†ì„±ì´ ìˆì„ ìˆ˜ ìˆìŒ
            title = getattr(toc_entry_item, 'title', None)
            
        elif isinstance(toc_entry_item, tuple) and len(toc_entry_item) == 2:
            # TOC í•­ëª©ì´ íŠœí”Œì¸ ê²½ìš° (ì˜ˆ: (EpubHtml, ì œëª©_ë¬¸ìì—´)) ì²˜ë¦¬
            possible_html_item, possible_title = toc_entry_item
            if isinstance(possible_html_item, epub.EpubHtml):
                href = possible_html_item.href
                title = possible_title # ì œëª©ì€ íŠœí”Œì˜ ë‘ ë²ˆì§¸ ìš”ì†Œ
            
            # íŠœí”Œì˜ ì²« ë²ˆì§¸ ìš”ì†Œê°€ (Sectionê³¼ ê°™ì€) ì»¨í…Œì´ë„ˆì´ê±°ë‚˜
            # ë‹¤ë¥¸ ì¤‘ì²©ëœ êµ¬ì¡°ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°
            if hasattr(possible_html_item, 'subitems') and possible_html_item.subitems:
                for sub_item in possible_html_item.subitems:
                    yield from process_toc_item_recursively(sub_item)
            elif isinstance(possible_html_item, epub.Section): # Sectionì€ í•˜ìœ„ í•­ëª©ì„ ê°€ì§ˆ ìˆ˜ ìˆìŒ
                for sub_item in possible_html_item.subitems:
                    yield from process_toc_item_recursively(sub_item)
        
        # ì•µì»¤(#)ë¥¼ ì œê±°í•˜ì—¬ href ì •ê·œí™”
        if href:
            normalized_href = href.split('#')[0]
            yield (normalized_href, title.strip() if title else "")

    # book.tocë¥¼ ë°˜ë³µí•˜ì—¬ toc_href_to_title ë§µ ì±„ìš°ê¸°
    for toc_entry in book.toc:
        for href, title in process_toc_item_recursively(toc_entry):
            # ì œëª©ì´ ìˆê±°ë‚˜ ìƒˆë¡œìš´ href í•­ëª©ì¸ ê²½ìš°ì—ë§Œ ì¶”ê°€
            if title or href not in toc_href_to_title:
                toc_href_to_title[href] = title

    # ì´ì œ ëª¨ë“  ë¬¸ì„œ í•­ëª©ì„ ë°˜ë³µí•˜ì—¬ ì½˜í…ì¸  ì¶”ì¶œ ë° ìµœì ì˜ ì œëª© ì ìš©
    for item in book.get_items():
        if item.get_type() == epub.ITEM_DOCUMENT: # HTML ì½˜í…ì¸  íŒŒì¼ì¸ ê²½ìš°
            soup = BeautifulSoup(item.get_content(), "html.parser")
            
            chapter_title = ""
            # TOC hrefì™€ ì¼ì¹˜í•˜ë„ë¡ í•­ëª©ì˜ íŒŒì¼ ì´ë¦„ì„ ì •ê·œí™”
            item_file_name_normalized = item.file_name.split('#')[0]

            # ìš°ì„ ìˆœìœ„ 1: TOC ë§¤í•‘ì—ì„œ ì œëª© ê°€ì ¸ì˜¤ê¸°
            if item_file_name_normalized in toc_href_to_title and toc_href_to_title[item_file_name_normalized]:
                chapter_title = toc_href_to_title[item_file_name_normalized]
            
            # ìš°ì„ ìˆœìœ„ 2: HTML <title> íƒœê·¸ì—ì„œ ì œëª© ê°€ì ¸ì˜¤ê¸°
            if not chapter_title:
                title_tag = soup.find('title')
                if title_tag and title_tag.string:
                    chapter_title = title_tag.string.strip()
            
            # ìš°ì„ ìˆœìœ„ 3: HTML ì½˜í…ì¸ ì˜ ì²« ë²ˆì§¸ í—¤ë”©(h1-h6)ì—ì„œ ì œëª© ê°€ì ¸ì˜¤ê¸°
            if not chapter_title:
                for h_level in range(1, 7): # h1, h2, ..., h6 í™•ì¸
                    heading_tag = soup.find(f'h{h_level}')
                    if heading_tag and heading_tag.get_text(strip=True):
                        chapter_title = heading_tag.get_text(strip=True)
                        break # ì²« ë²ˆì§¸ í—¤ë”©ì„ ì°¾ìœ¼ë©´ ì¤‘ì§€
            
            # ìµœì¢… ëŒ€ì²´: ì œëª©ì„ ì°¾ì§€ ëª»í•˜ë©´ "Unnamed Chapter" í• ë‹¹
            if not chapter_title:
                chapter_title = f"Unnamed Chapter {len(titles)+1}"
            
            # ì±•í„°ì˜ ê¹¨ë—í•œ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ
            text = soup.get_text(separator="\n", strip=True)
            
            # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆëŠ” ì±•í„°ë§Œ í¬í•¨ (ì˜ˆ: 100ì ì´ìƒ)
            if len(text.strip()) > 100:
                titles.append(chapter_title)
                chapters.append(text)
                
    return titles, chapters

def create_embeddings(texts):
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    return embedder.encode(texts)

def build_faiss_index(embeddings):
    """ì„ë² ë”©ìœ¼ë¡œ FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."""
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index

def ask_gemini(prompt_text):
    """Gemini ëª¨ë¸ì— ì§ˆë¬¸ì„ í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        response = model.generate_content(prompt_text)
        return response.text.strip()
    except Exception as e:
        return f"âŒ Gemini ì‘ë‹µ ì˜¤ë¥˜: {e}"

# --- ì•± UI ---
st.set_page_config(page_title="ğŸ“š ePub ì±—ë´‡", layout="wide")
st.title("ğŸ“– ePub ì±•í„° ìš”ì•½ & ì±—ë´‡")

uploaded_file = st.file_uploader("ğŸ“¤ ePub íŒŒì¼ ì—…ë¡œë“œ", type="epub")

if uploaded_file:
    # ì—…ë¡œë“œëœ ePub íŒŒì¼ì„ ì„ì‹œ ìœ„ì¹˜ì— ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".epub") as tmp_file:
        tmp_file.write(uploaded_file.read())
        epub_path = tmp_file.name

    with st.spinner("ğŸ“š ePub íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
        titles, chapters = extract_epub_chapters(epub_path)

    if not titles:
        st.error("âŒ ì±•í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ePub êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.success(f"âœ… {len(titles)}ê°œì˜ ì±•í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        # ì±•í„° ì„ íƒì„ ìœ„í•œ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ìƒì„±
        chapter_idx = st.selectbox("ğŸ” ìš”ì•½í•  ì±•í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”:", range(len(titles)), format_func=lambda i: titles[i])

        selected_text = chapters[chapter_idx]

        with st.spinner("ğŸ§  ì„ë² ë”© ë° ìš”ì•½ ì¤‘..."):
            selected_embedding = create_embeddings([selected_text])
            index = build_faiss_index(np.array(selected_embedding))

            # í•œêµ­ì–´ ë° ì˜ì–´ ìš”ì•½ ìš”ì²­
            summary_prompt_ko = f"ë‹¤ìŒ ê¸€ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜:\n\n{selected_text[:4000]}"
            summary_prompt_en = f"Summarize the following text in English:\n\n{selected_text[:4000]}"

            summary_ko = ask_gemini(summary_prompt_ko)
            summary_en = ask_gemini(summary_prompt_en)

        st.subheader("ğŸ“ ìš”ì•½")
        st.markdown("**ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš”ì•½:**")
        st.write(summary_ko)
        st.markdown("**ğŸ‡ºğŸ‡¸ English Summary:**")
        st.write(summary_en)

        st.divider()
        st.subheader("ğŸ’¬ ì±•í„° ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")

        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒí•œ ì±•í„° ê¸°ì¤€)")
        if question:
            question_embedding = embedder.encode([question])
            # ì‹¤ì œ RAGì—ì„œëŠ” ì „ì²´ ì¸ë±ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì„ íƒëœ ì±•í„°ì˜ ì„ë² ë”©ë§Œ ì‚¬ìš©
            D, I = index.search(np.array(question_embedding), k=1) 
            context = selected_text
            prompt = f"""
ë‹¤ìŒ ê¸€ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì¤˜.
---
{context}
---
ì§ˆë¬¸: {question}
"""
            answer = ask_gemini(prompt)
            st.markdown("**ğŸ¤– ë‹µë³€:**")
            st.write(answer)

        st.divider()
        st.subheader("ğŸŒ ì „ì²´ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")

        global_question = st.text_input("ì „ì²´ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”")
        if global_question:
            with st.spinner("ì „ì²´ ë¬¸ì„œì—ì„œ ë‹µë³€ ì¤‘..."):
                full_text = "\n".join(chapters)
                # ëª¨ë¸ ì…ë ¥ ì œí•œì„ ìœ„í•´ full_text ê¸¸ì´ ì¡°ì ˆ
                prompt = f"""
ë‹¤ìŒ ePub ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
---
{full_text[:8000]}
---
ì§ˆë¬¸: {global_question}
"""
                global_answer = ask_gemini(prompt)
                st.markdown("**ğŸŒ ì „ì²´ ë¬¸ì„œ ì‘ë‹µ:**")
                st.write(global_answer)

    try:
        # ì„ì‹œ ePub íŒŒì¼ ì •ë¦¬
        os.remove(epub_path)
    except Exception as e:
        st.error(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
