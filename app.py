import streamlit as st
import tempfile
import os
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from ebooklib import epub
from bs4 import BeautifulSoup

# --- ì´ˆê¸° ì„¤ì • ---
GEMINI_API_KEY = st.secrets.get("Key")
if not GEMINI_API_KEY:
    st.error("Gemini API key not found. Please add 'Key' to your secrets.")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)

@st.cache_resource
def load_gemini_model():
    return genai.GenerativeModel("models/gemini-1.5-flash")

@st.cache_resource
def load_embedder():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_gemini_model()
embedder = load_embedder()

# --- í•¨ìˆ˜ë“¤ ---

def extract_epub_chapters(epub_path):
    book = epub.read_epub(epub_path)
    titles, chapters = [], []

    # TOCì—ì„œ (title, href) ì¶”ì¶œ
    def flatten_toc(toc):
        result = []
        for item in toc:
            if isinstance(item, epub.Link):
                result.append((item.title, item.href))
            elif isinstance(item, tuple) and len(item) == 2:
                # (section_title, [subitems])
                # section_title = item[0]  # í•„ìš”ì‹œ ì‚¬ìš©
                result.extend(flatten_toc(item[1]))
            elif isinstance(item, list):
                result.extend(flatten_toc(item))
        return result

    toc_entries = flatten_toc(book.toc)

    for title, href in toc_entries:
        href_clean = href.split('#')[0]
        item = book.get_item_with_href(href_clean)
        if item is not None:
            soup = BeautifulSoup(item.get_content(), "html.parser")
            text = soup.get_text(separator="\n", strip=True)
            if len(text.strip()) > 100:  # ë‚´ìš© ì—†ëŠ” ì±•í„°ëŠ” ì œì™¸
                titles.append(title.strip())
                chapters.append(text)
    return titles, chapters

def create_embeddings(texts):
    return embedder.encode(texts)

def build_faiss_index(embeddings):
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index

def ask_gemini(prompt_text):
    try:
        response = model.generate_content(prompt_text)
        return response.text.strip()
    except Exception as e:
        return f"âŒ Gemini ì‘ë‹µ ì˜¤ë¥˜: {e}"

# --- ì•± UI ---

st.set_page_config(page_title="ğŸ“š ePub ì±—ë´‡", layout="wide")
st.title("ğŸ“– ePub ì±•í„° ìš”ì•½ & ì±—ë´‡")

uploaded_file = st.file_uploader("ğŸ“¤ ePub íŒŒì¼ ì—…ë¡œë“œ", type="epub")

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".epub") as tmp_file:
        tmp_file.write(uploaded_file.read())
        epub_path = tmp_file.name

    with st.spinner("ğŸ“š ePub íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
        titles, chapters = extract_epub_chapters(epub_path)

    if not titles:
        st.error("âŒ ì±•í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ePub êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.success(f"âœ… {len(titles)}ê°œì˜ ì±•í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        chapter_idx = st.selectbox("ğŸ” ìš”ì•½í•  ì±•í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”:", range(len(titles)), format_func=lambda i: titles[i])

        selected_text = chapters[chapter_idx]

        with st.spinner("ğŸ§  ì„ë² ë”© ë° ìš”ì•½ ì¤‘..."):
            selected_embedding = create_embeddings([selected_text])
            index = build_faiss_index(np.array(selected_embedding))

            # ìš”ì•½ ìš”ì²­
            summary_prompt_ko = f"ë‹¤ìŒ ê¸€ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜:\n\n{selected_text[:4000]}"
            summary_prompt_en = f"Summarize the following text in English:\n\n{selected_text[:4000]}"

            summary_ko = ask_gemini(summary_prompt_ko)
            summary_en = ask_gemini(summary_prompt_en)

        st.subheader("ğŸ“ ìš”ì•½")
        st.markdown("**ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš”ì•½:**")
        st.write(summary_ko)
        st.markdown("**ğŸ‡ºğŸ‡¸ English Summary:**")
        st.write(summary_en)

        st.divider()
        st.subheader("ğŸ’¬ ì±•í„° ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")

        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒí•œ ì±•í„° ê¸°ì¤€)")
        if question:
            question_embedding = embedder.encode([question])
            D, I = index.search(np.array(question_embedding), k=1)
            context = selected_text
            prompt = f"""
ë‹¤ìŒ ê¸€ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì¤˜.

---

{context}

---

ì§ˆë¬¸: {question}
"""
            answer = ask_gemini(prompt)
            st.markdown("**ğŸ¤– ë‹µë³€:**")
            st.write(answer)

        st.divider()
        st.subheader("ğŸŒ ì „ì²´ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ")

        global_question = st.text_input("ì „ì²´ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”")
        if global_question:
            with st.spinner("ì „ì²´ ë¬¸ì„œì—ì„œ ë‹µë³€ ì¤‘..."):
                full_text = "\n".join(chapters)
                prompt = f"""
ë‹¤ìŒ ePub ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

---

{full_text[:8000]}

---

ì§ˆë¬¸: {global_question}
"""
                global_answer = ask_gemini(prompt)
                st.markdown("**ğŸŒ ì „ì²´ ë¬¸ì„œ ì‘ë‹µ:**")
                st.write(global_answer)

    try:
        os.remove(epub_path)
    except:
        pass
